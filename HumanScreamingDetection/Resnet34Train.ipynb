{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:44.992750200Z",
     "start_time": "2023-10-13T03:48:40.461215600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 3295\n    Root location: Data/Images\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 862), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n           )"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'Data/Images' #looking in subfolder train\n",
    "\n",
    "scream_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((64,862)),\n",
    "                                  transforms.ToTensor()])\n",
    ")\n",
    "scream_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:45.081573700Z",
     "start_time": "2023-10-13T03:48:44.993750900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'not': 0, 'scream': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=scream_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:45.085123Z",
     "start_time": "2023-10-13T03:48:45.081573700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 2636\n",
      "Testing size: 659\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(scream_dataset))\n",
    "test_size = len(scream_dataset) - train_size\n",
    "scream_train_dataset, scream_test_dataset = torch.utils.data.random_split(scream_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(scream_train_dataset))\n",
    "print(\"Testing size:\",len(scream_test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:45.106874500Z",
     "start_time": "2023-10-13T03:48:45.087139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 1746, 1: 890})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in scream_train_dataset]\n",
    "Counter(train_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:50.894137400Z",
     "start_time": "2023-10-13T03:48:45.106874500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_test_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:50.897051500Z",
     "start_time": "2023-10-13T03:48:50.893137400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.7098, 0.6549, 0.6549,  ..., 0.4667, 0.5647, 0.7294],\n         [0.5059, 0.5843, 0.7725,  ..., 0.4549, 0.6863, 0.7725],\n         [0.2392, 0.6235, 0.7412,  ..., 0.5843, 0.8235, 0.6471],\n         ...,\n         [0.2157, 0.2588, 0.2784,  ..., 0.2824, 0.2745, 0.2745],\n         [0.2196, 0.2667, 0.2784,  ..., 0.2784, 0.2784, 0.2784],\n         [0.2235, 0.2784, 0.2706,  ..., 0.2745, 0.2706, 0.2745]],\n\n        [[0.8667, 0.8588, 0.8588,  ..., 0.8157, 0.8392, 0.8706],\n         [0.8275, 0.8431, 0.8745,  ..., 0.8157, 0.8627, 0.8745],\n         [0.7333, 0.8510, 0.8706,  ..., 0.8431, 0.8824, 0.8549],\n         ...,\n         [0.3490, 0.2392, 0.1490,  ..., 0.1373, 0.0549, 0.1843],\n         [0.3373, 0.2157, 0.1725,  ..., 0.1451, 0.0824, 0.1725],\n         [0.3333, 0.0667, 0.0314,  ..., 0.0431, 0.0314, 0.1882]],\n\n        [[0.1686, 0.2000, 0.2000,  ..., 0.3216, 0.2627, 0.1529],\n         [0.2980, 0.2471, 0.1294,  ..., 0.3294, 0.1804, 0.1294],\n         [0.4549, 0.2196, 0.1490,  ..., 0.2471, 0.1059, 0.2078],\n         ...,\n         [0.5490, 0.5176, 0.4627,  ..., 0.4549, 0.3804, 0.4863],\n         [0.5451, 0.5059, 0.4824,  ..., 0.4588, 0.4039, 0.4824],\n         [0.5451, 0.3882, 0.3569,  ..., 0.3686, 0.3569, 0.4902]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = train_dataloader.dataset[0][0]\n",
    "td"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:50.945169100Z",
     "start_time": "2023-10-13T03:48:50.897051500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 862])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:50.952170200Z",
     "start_time": "2023-10-13T03:48:50.929169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:52.170221Z",
     "start_time": "2023-10-13T03:48:50.931169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "import torch\n",
    "\n",
    "model = resnet34()\n",
    "model.fc = nn.Linear(512,2)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:52.919060Z",
     "start_time": "2023-10-13T03:48:52.170221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T03:48:52.926513100Z",
     "start_time": "2023-10-13T03:48:52.920059700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.040950  [    0/ 2636]\n",
      "loss: 0.033444  [  640/ 2636]\n",
      "loss: 0.034684  [ 1280/ 2636]\n",
      "loss: 0.080261  [ 1920/ 2636]\n",
      "loss: 0.084260  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005836\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.025030  [    0/ 2636]\n",
      "loss: 0.011634  [  640/ 2636]\n",
      "loss: 0.012492  [ 1280/ 2636]\n",
      "loss: 0.116268  [ 1920/ 2636]\n",
      "loss: 0.035474  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005059\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.105061  [    0/ 2636]\n",
      "loss: 0.054576  [  640/ 2636]\n",
      "loss: 0.078936  [ 1280/ 2636]\n",
      "loss: 0.027302  [ 1920/ 2636]\n",
      "loss: 0.019530  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005394\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.064643  [    0/ 2636]\n",
      "loss: 0.027754  [  640/ 2636]\n",
      "loss: 0.016308  [ 1280/ 2636]\n",
      "loss: 0.026558  [ 1920/ 2636]\n",
      "loss: 0.016095  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005599\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.019866  [    0/ 2636]\n",
      "loss: 0.040143  [  640/ 2636]\n",
      "loss: 0.038069  [ 1280/ 2636]\n",
      "loss: 0.024520  [ 1920/ 2636]\n",
      "loss: 0.108919  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005458\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.029582  [    0/ 2636]\n",
      "loss: 0.033639  [  640/ 2636]\n",
      "loss: 0.016397  [ 1280/ 2636]\n",
      "loss: 0.018628  [ 1920/ 2636]\n",
      "loss: 0.012903  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.006435\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.023553  [    0/ 2636]\n",
      "loss: 0.034943  [  640/ 2636]\n",
      "loss: 0.038790  [ 1280/ 2636]\n",
      "loss: 0.048840  [ 1920/ 2636]\n",
      "loss: 0.026668  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005351\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.012543  [    0/ 2636]\n",
      "loss: 0.100389  [  640/ 2636]\n",
      "loss: 0.042796  [ 1280/ 2636]\n",
      "loss: 0.061159  [ 1920/ 2636]\n",
      "loss: 0.050277  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005403\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.035629  [    0/ 2636]\n",
      "loss: 0.020196  [  640/ 2636]\n",
      "loss: 0.075922  [ 1280/ 2636]\n",
      "loss: 0.045716  [ 1920/ 2636]\n",
      "loss: 0.022916  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005464\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.071543  [    0/ 2636]\n",
      "loss: 0.026052  [  640/ 2636]\n",
      "loss: 0.124098  [ 1280/ 2636]\n",
      "loss: 0.023275  [ 1920/ 2636]\n",
      "loss: 0.040777  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005404\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.044425  [    0/ 2636]\n",
      "loss: 0.016548  [  640/ 2636]\n",
      "loss: 0.035283  [ 1280/ 2636]\n",
      "loss: 0.071362  [ 1920/ 2636]\n",
      "loss: 0.027043  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005142\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.062985  [    0/ 2636]\n",
      "loss: 0.057811  [  640/ 2636]\n",
      "loss: 0.038339  [ 1280/ 2636]\n",
      "loss: 0.052782  [ 1920/ 2636]\n",
      "loss: 0.066485  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005674\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.074249  [    0/ 2636]\n",
      "loss: 0.061744  [  640/ 2636]\n",
      "loss: 0.027281  [ 1280/ 2636]\n",
      "loss: 0.014113  [ 1920/ 2636]\n",
      "loss: 0.010592  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005073\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.033929  [    0/ 2636]\n",
      "loss: 0.015971  [  640/ 2636]\n",
      "loss: 0.026593  [ 1280/ 2636]\n",
      "loss: 0.052163  [ 1920/ 2636]\n",
      "loss: 0.009004  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005408\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.095244  [    0/ 2636]\n",
      "loss: 0.022449  [  640/ 2636]\n",
      "loss: 0.062306  [ 1280/ 2636]\n",
      "loss: 0.023246  [ 1920/ 2636]\n",
      "loss: 0.092962  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005220\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.027951  [    0/ 2636]\n",
      "loss: 0.042468  [  640/ 2636]\n",
      "loss: 0.031881  [ 1280/ 2636]\n",
      "loss: 0.039368  [ 1920/ 2636]\n",
      "loss: 0.050290  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005875\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.055329  [    0/ 2636]\n",
      "loss: 0.026393  [  640/ 2636]\n",
      "loss: 0.086576  [ 1280/ 2636]\n",
      "loss: 0.062960  [ 1920/ 2636]\n",
      "loss: 0.104254  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005466\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.031443  [    0/ 2636]\n",
      "loss: 0.023253  [  640/ 2636]\n",
      "loss: 0.037609  [ 1280/ 2636]\n",
      "loss: 0.012069  [ 1920/ 2636]\n",
      "loss: 0.023466  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.006795\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.047996  [    0/ 2636]\n",
      "loss: 0.072273  [  640/ 2636]\n",
      "loss: 0.057212  [ 1280/ 2636]\n",
      "loss: 0.027356  [ 1920/ 2636]\n",
      "loss: 0.030079  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.004980\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.051963  [    0/ 2636]\n",
      "loss: 0.056083  [  640/ 2636]\n",
      "loss: 0.072053  [ 1280/ 2636]\n",
      "loss: 0.015699  [ 1920/ 2636]\n",
      "loss: 0.037111  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.004966\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.120692  [    0/ 2636]\n",
      "loss: 0.051506  [  640/ 2636]\n",
      "loss: 0.094676  [ 1280/ 2636]\n",
      "loss: 0.030957  [ 1920/ 2636]\n",
      "loss: 0.065824  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.1%, avg loss: 0.005429\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.032093  [    0/ 2636]\n",
      "loss: 0.048553  [  640/ 2636]\n",
      "loss: 0.146234  [ 1280/ 2636]\n",
      "loss: 0.046515  [ 1920/ 2636]\n",
      "loss: 0.013871  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.006541\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.029308  [    0/ 2636]\n",
      "loss: 0.067499  [  640/ 2636]\n",
      "loss: 0.131298  [ 1280/ 2636]\n",
      "loss: 0.011138  [ 1920/ 2636]\n",
      "loss: 0.010628  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005664\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.029339  [    0/ 2636]\n",
      "loss: 0.019093  [  640/ 2636]\n",
      "loss: 0.028053  [ 1280/ 2636]\n",
      "loss: 0.219238  [ 1920/ 2636]\n",
      "loss: 0.124910  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005428\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.025405  [    0/ 2636]\n",
      "loss: 0.041872  [  640/ 2636]\n",
      "loss: 0.013139  [ 1280/ 2636]\n",
      "loss: 0.012963  [ 1920/ 2636]\n",
      "loss: 0.026895  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005344\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.039648  [    0/ 2636]\n",
      "loss: 0.112249  [  640/ 2636]\n",
      "loss: 0.045833  [ 1280/ 2636]\n",
      "loss: 0.090781  [ 1920/ 2636]\n",
      "loss: 0.069612  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005376\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.024507  [    0/ 2636]\n",
      "loss: 0.021828  [  640/ 2636]\n",
      "loss: 0.009386  [ 1280/ 2636]\n",
      "loss: 0.074151  [ 1920/ 2636]\n",
      "loss: 0.061374  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005670\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.019501  [    0/ 2636]\n",
      "loss: 0.032911  [  640/ 2636]\n",
      "loss: 0.044425  [ 1280/ 2636]\n",
      "loss: 0.032170  [ 1920/ 2636]\n",
      "loss: 0.023525  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005204\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.064082  [    0/ 2636]\n",
      "loss: 0.024380  [  640/ 2636]\n",
      "loss: 0.088900  [ 1280/ 2636]\n",
      "loss: 0.066564  [ 1920/ 2636]\n",
      "loss: 0.018897  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005749\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.054266  [    0/ 2636]\n",
      "loss: 0.088397  [  640/ 2636]\n",
      "loss: 0.027123  [ 1280/ 2636]\n",
      "loss: 0.076747  [ 1920/ 2636]\n",
      "loss: 0.021812  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005555\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.049203  [    0/ 2636]\n",
      "loss: 0.037157  [  640/ 2636]\n",
      "loss: 0.007597  [ 1280/ 2636]\n",
      "loss: 0.183427  [ 1920/ 2636]\n",
      "loss: 0.355035  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.005069\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.025932  [    0/ 2636]\n",
      "loss: 0.029469  [  640/ 2636]\n",
      "loss: 0.028616  [ 1280/ 2636]\n",
      "loss: 0.049898  [ 1920/ 2636]\n",
      "loss: 0.048915  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.004967\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.015179  [    0/ 2636]\n",
      "loss: 0.052476  [  640/ 2636]\n",
      "loss: 0.054122  [ 1280/ 2636]\n",
      "loss: 0.044763  [ 1920/ 2636]\n",
      "loss: 0.036953  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005272\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.027482  [    0/ 2636]\n",
      "loss: 0.032736  [  640/ 2636]\n",
      "loss: 0.035054  [ 1280/ 2636]\n",
      "loss: 0.089298  [ 1920/ 2636]\n",
      "loss: 0.011474  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.1%, avg loss: 0.005362\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.158655  [    0/ 2636]\n",
      "loss: 0.073300  [  640/ 2636]\n",
      "loss: 0.025685  [ 1280/ 2636]\n",
      "loss: 0.039315  [ 1920/ 2636]\n",
      "loss: 0.039746  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.1%, avg loss: 0.005230\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.019866  [    0/ 2636]\n",
      "loss: 0.036747  [  640/ 2636]\n",
      "loss: 0.032659  [ 1280/ 2636]\n",
      "loss: 0.034343  [ 1920/ 2636]\n",
      "loss: 0.015212  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005506\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.035825  [    0/ 2636]\n",
      "loss: 0.052790  [  640/ 2636]\n",
      "loss: 0.028076  [ 1280/ 2636]\n",
      "loss: 0.094145  [ 1920/ 2636]\n",
      "loss: 0.011404  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005008\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.067072  [    0/ 2636]\n",
      "loss: 0.026522  [  640/ 2636]\n",
      "loss: 0.049620  [ 1280/ 2636]\n",
      "loss: 0.023686  [ 1920/ 2636]\n",
      "loss: 0.097178  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005250\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.025920  [    0/ 2636]\n",
      "loss: 0.046644  [  640/ 2636]\n",
      "loss: 0.039279  [ 1280/ 2636]\n",
      "loss: 0.114400  [ 1920/ 2636]\n",
      "loss: 0.026786  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005419\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.014683  [    0/ 2636]\n",
      "loss: 0.040878  [  640/ 2636]\n",
      "loss: 0.034107  [ 1280/ 2636]\n",
      "loss: 0.084448  [ 1920/ 2636]\n",
      "loss: 0.030000  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.005000\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.046029  [    0/ 2636]\n",
      "loss: 0.099263  [  640/ 2636]\n",
      "loss: 0.018825  [ 1280/ 2636]\n",
      "loss: 0.060625  [ 1920/ 2636]\n",
      "loss: 0.020976  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005244\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.045561  [    0/ 2636]\n",
      "loss: 0.080553  [  640/ 2636]\n",
      "loss: 0.051176  [ 1280/ 2636]\n",
      "loss: 0.122481  [ 1920/ 2636]\n",
      "loss: 0.037199  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005428\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.029131  [    0/ 2636]\n",
      "loss: 0.023399  [  640/ 2636]\n",
      "loss: 0.048632  [ 1280/ 2636]\n",
      "loss: 0.031743  [ 1920/ 2636]\n",
      "loss: 0.031661  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.005474\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.061771  [    0/ 2636]\n",
      "loss: 0.033136  [  640/ 2636]\n",
      "loss: 0.128255  [ 1280/ 2636]\n",
      "loss: 0.039846  [ 1920/ 2636]\n",
      "loss: 0.015524  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.005271\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.040330  [    0/ 2636]\n",
      "loss: 0.036910  [  640/ 2636]\n",
      "loss: 0.026475  [ 1280/ 2636]\n",
      "loss: 0.034754  [ 1920/ 2636]\n",
      "loss: 0.073887  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005023\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.026908  [    0/ 2636]\n",
      "loss: 0.034176  [  640/ 2636]\n",
      "loss: 0.014863  [ 1280/ 2636]\n",
      "loss: 0.060688  [ 1920/ 2636]\n",
      "loss: 0.021318  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005277\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.018609  [    0/ 2636]\n",
      "loss: 0.084031  [  640/ 2636]\n",
      "loss: 0.032350  [ 1280/ 2636]\n",
      "loss: 0.008182  [ 1920/ 2636]\n",
      "loss: 0.064154  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005757\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.065560  [    0/ 2636]\n",
      "loss: 0.067597  [  640/ 2636]\n",
      "loss: 0.026063  [ 1280/ 2636]\n",
      "loss: 0.027518  [ 1920/ 2636]\n",
      "loss: 0.037609  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005093\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.011751  [    0/ 2636]\n",
      "loss: 0.010180  [  640/ 2636]\n",
      "loss: 0.019666  [ 1280/ 2636]\n",
      "loss: 0.014487  [ 1920/ 2636]\n",
      "loss: 0.055697  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005817\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.046896  [    0/ 2636]\n",
      "loss: 0.022485  [  640/ 2636]\n",
      "loss: 0.094648  [ 1280/ 2636]\n",
      "loss: 0.008530  [ 1920/ 2636]\n",
      "loss: 0.022589  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005164\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.072215  [    0/ 2636]\n",
      "loss: 0.026851  [  640/ 2636]\n",
      "loss: 0.015113  [ 1280/ 2636]\n",
      "loss: 0.106475  [ 1920/ 2636]\n",
      "loss: 0.050318  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005289\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.011872  [    0/ 2636]\n",
      "loss: 0.016029  [  640/ 2636]\n",
      "loss: 0.030680  [ 1280/ 2636]\n",
      "loss: 0.130059  [ 1920/ 2636]\n",
      "loss: 0.030162  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005292\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.054398  [    0/ 2636]\n",
      "loss: 0.171336  [  640/ 2636]\n",
      "loss: 0.026881  [ 1280/ 2636]\n",
      "loss: 0.071911  [ 1920/ 2636]\n",
      "loss: 0.027620  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.006169\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.019645  [    0/ 2636]\n",
      "loss: 0.030767  [  640/ 2636]\n",
      "loss: 0.040058  [ 1280/ 2636]\n",
      "loss: 0.042284  [ 1920/ 2636]\n",
      "loss: 0.112913  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005528\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.038868  [    0/ 2636]\n",
      "loss: 0.085785  [  640/ 2636]\n",
      "loss: 0.037782  [ 1280/ 2636]\n",
      "loss: 0.064676  [ 1920/ 2636]\n",
      "loss: 0.038697  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005151\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.023845  [    0/ 2636]\n",
      "loss: 0.049099  [  640/ 2636]\n",
      "loss: 0.017923  [ 1280/ 2636]\n",
      "loss: 0.054765  [ 1920/ 2636]\n",
      "loss: 0.054384  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005516\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.024310  [    0/ 2636]\n",
      "loss: 0.064897  [  640/ 2636]\n",
      "loss: 0.041448  [ 1280/ 2636]\n",
      "loss: 0.033219  [ 1920/ 2636]\n",
      "loss: 0.020227  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005050\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.079382  [    0/ 2636]\n",
      "loss: 0.010965  [  640/ 2636]\n",
      "loss: 0.093648  [ 1280/ 2636]\n",
      "loss: 0.136920  [ 1920/ 2636]\n",
      "loss: 0.015919  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005227\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.036808  [    0/ 2636]\n",
      "loss: 0.028283  [  640/ 2636]\n",
      "loss: 0.016351  [ 1280/ 2636]\n",
      "loss: 0.040707  [ 1920/ 2636]\n",
      "loss: 0.055921  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005505\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.012270  [    0/ 2636]\n",
      "loss: 0.020734  [  640/ 2636]\n",
      "loss: 0.036268  [ 1280/ 2636]\n",
      "loss: 0.021736  [ 1920/ 2636]\n",
      "loss: 0.012392  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.006360\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.056858  [    0/ 2636]\n",
      "loss: 0.015667  [  640/ 2636]\n",
      "loss: 0.018382  [ 1280/ 2636]\n",
      "loss: 0.030027  [ 1920/ 2636]\n",
      "loss: 0.084454  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005837\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.023254  [    0/ 2636]\n",
      "loss: 0.093987  [  640/ 2636]\n",
      "loss: 0.036709  [ 1280/ 2636]\n",
      "loss: 0.028973  [ 1920/ 2636]\n",
      "loss: 0.018177  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005162\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.019556  [    0/ 2636]\n",
      "loss: 0.017281  [  640/ 2636]\n",
      "loss: 0.081462  [ 1280/ 2636]\n",
      "loss: 0.073618  [ 1920/ 2636]\n",
      "loss: 0.100154  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005167\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.019320  [    0/ 2636]\n",
      "loss: 0.017950  [  640/ 2636]\n",
      "loss: 0.050721  [ 1280/ 2636]\n",
      "loss: 0.035913  [ 1920/ 2636]\n",
      "loss: 0.015158  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005009\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.033885  [    0/ 2636]\n",
      "loss: 0.023632  [  640/ 2636]\n",
      "loss: 0.044860  [ 1280/ 2636]\n",
      "loss: 0.051931  [ 1920/ 2636]\n",
      "loss: 0.049488  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005411\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.042869  [    0/ 2636]\n",
      "loss: 0.106333  [  640/ 2636]\n",
      "loss: 0.080335  [ 1280/ 2636]\n",
      "loss: 0.031492  [ 1920/ 2636]\n",
      "loss: 0.067414  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005702\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.060969  [    0/ 2636]\n",
      "loss: 0.071532  [  640/ 2636]\n",
      "loss: 0.048956  [ 1280/ 2636]\n",
      "loss: 0.017779  [ 1920/ 2636]\n",
      "loss: 0.034298  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005246\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.029038  [    0/ 2636]\n",
      "loss: 0.081740  [  640/ 2636]\n",
      "loss: 0.021657  [ 1280/ 2636]\n",
      "loss: 0.022381  [ 1920/ 2636]\n",
      "loss: 0.011951  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005100\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.013666  [    0/ 2636]\n",
      "loss: 0.028938  [  640/ 2636]\n",
      "loss: 0.050339  [ 1280/ 2636]\n",
      "loss: 0.088848  [ 1920/ 2636]\n",
      "loss: 0.030550  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005079\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.030797  [    0/ 2636]\n",
      "loss: 0.073935  [  640/ 2636]\n",
      "loss: 0.028087  [ 1280/ 2636]\n",
      "loss: 0.068684  [ 1920/ 2636]\n",
      "loss: 0.136598  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005205\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.035782  [    0/ 2636]\n",
      "loss: 0.013804  [  640/ 2636]\n",
      "loss: 0.023070  [ 1280/ 2636]\n",
      "loss: 0.020920  [ 1920/ 2636]\n",
      "loss: 0.023529  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.006075\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.015257  [    0/ 2636]\n",
      "loss: 0.011764  [  640/ 2636]\n",
      "loss: 0.016174  [ 1280/ 2636]\n",
      "loss: 0.022139  [ 1920/ 2636]\n",
      "loss: 0.056078  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005623\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.023484  [    0/ 2636]\n",
      "loss: 0.033851  [  640/ 2636]\n",
      "loss: 0.036200  [ 1280/ 2636]\n",
      "loss: 0.030278  [ 1920/ 2636]\n",
      "loss: 0.043184  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 90.9%, avg loss: 0.005574\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.028534  [    0/ 2636]\n",
      "loss: 0.011468  [  640/ 2636]\n",
      "loss: 0.046521  [ 1280/ 2636]\n",
      "loss: 0.028923  [ 1920/ 2636]\n",
      "loss: 0.077499  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.1%, avg loss: 0.006527\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.009310  [    0/ 2636]\n",
      "loss: 0.027148  [  640/ 2636]\n",
      "loss: 0.060827  [ 1280/ 2636]\n",
      "loss: 0.032754  [ 1920/ 2636]\n",
      "loss: 0.049864  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.005625\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.047112  [    0/ 2636]\n",
      "loss: 0.032147  [  640/ 2636]\n",
      "loss: 0.088865  [ 1280/ 2636]\n",
      "loss: 0.078194  [ 1920/ 2636]\n",
      "loss: 0.049477  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005194\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.045396  [    0/ 2636]\n",
      "loss: 0.050436  [  640/ 2636]\n",
      "loss: 0.029982  [ 1280/ 2636]\n",
      "loss: 0.024172  [ 1920/ 2636]\n",
      "loss: 0.038967  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.006211\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.019593  [    0/ 2636]\n",
      "loss: 0.014454  [  640/ 2636]\n",
      "loss: 0.042681  [ 1280/ 2636]\n",
      "loss: 0.018383  [ 1920/ 2636]\n",
      "loss: 0.044559  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.1%, avg loss: 0.005352\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.097622  [    0/ 2636]\n",
      "loss: 0.035507  [  640/ 2636]\n",
      "loss: 0.025363  [ 1280/ 2636]\n",
      "loss: 0.014487  [ 1920/ 2636]\n",
      "loss: 0.011886  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005300\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.033275  [    0/ 2636]\n",
      "loss: 0.072536  [  640/ 2636]\n",
      "loss: 0.024970  [ 1280/ 2636]\n",
      "loss: 0.081580  [ 1920/ 2636]\n",
      "loss: 0.053010  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005624\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.094437  [    0/ 2636]\n",
      "loss: 0.035917  [  640/ 2636]\n",
      "loss: 0.020834  [ 1280/ 2636]\n",
      "loss: 0.022884  [ 1920/ 2636]\n",
      "loss: 0.105684  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.2%, avg loss: 0.005319\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.030448  [    0/ 2636]\n",
      "loss: 0.034762  [  640/ 2636]\n",
      "loss: 0.045963  [ 1280/ 2636]\n",
      "loss: 0.015662  [ 1920/ 2636]\n",
      "loss: 0.026304  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.006167\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.043453  [    0/ 2636]\n",
      "loss: 0.013199  [  640/ 2636]\n",
      "loss: 0.127749  [ 1280/ 2636]\n",
      "loss: 0.073892  [ 1920/ 2636]\n",
      "loss: 0.031308  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.0%, avg loss: 0.005042\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.120884  [    0/ 2636]\n",
      "loss: 0.093020  [  640/ 2636]\n",
      "loss: 0.054947  [ 1280/ 2636]\n",
      "loss: 0.087577  [ 1920/ 2636]\n",
      "loss: 0.016576  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.005187\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.043894  [    0/ 2636]\n",
      "loss: 0.137529  [  640/ 2636]\n",
      "loss: 0.023464  [ 1280/ 2636]\n",
      "loss: 0.037116  [ 1920/ 2636]\n",
      "loss: 0.035972  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.0%, avg loss: 0.006020\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.039253  [    0/ 2636]\n",
      "loss: 0.071679  [  640/ 2636]\n",
      "loss: 0.050679  [ 1280/ 2636]\n",
      "loss: 0.040302  [ 1920/ 2636]\n",
      "loss: 0.009954  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.006167\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.035607  [    0/ 2636]\n",
      "loss: 0.018997  [  640/ 2636]\n",
      "loss: 0.026863  [ 1280/ 2636]\n",
      "loss: 0.024955  [ 1920/ 2636]\n",
      "loss: 0.042390  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005333\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.088873  [    0/ 2636]\n",
      "loss: 0.065104  [  640/ 2636]\n",
      "loss: 0.031848  [ 1280/ 2636]\n",
      "loss: 0.100448  [ 1920/ 2636]\n",
      "loss: 0.064068  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.4%, avg loss: 0.005477\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.054788  [    0/ 2636]\n",
      "loss: 0.103647  [  640/ 2636]\n",
      "loss: 0.028266  [ 1280/ 2636]\n",
      "loss: 0.018737  [ 1920/ 2636]\n",
      "loss: 0.023497  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005008\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.057530  [    0/ 2636]\n",
      "loss: 0.182842  [  640/ 2636]\n",
      "loss: 0.045263  [ 1280/ 2636]\n",
      "loss: 0.043950  [ 1920/ 2636]\n",
      "loss: 0.011632  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005369\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.035114  [    0/ 2636]\n",
      "loss: 0.120829  [  640/ 2636]\n",
      "loss: 0.051144  [ 1280/ 2636]\n",
      "loss: 0.020285  [ 1920/ 2636]\n",
      "loss: 0.093141  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.004987\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.052859  [    0/ 2636]\n",
      "loss: 0.022713  [  640/ 2636]\n",
      "loss: 0.021470  [ 1280/ 2636]\n",
      "loss: 0.038198  [ 1920/ 2636]\n",
      "loss: 0.061888  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005719\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.057660  [    0/ 2636]\n",
      "loss: 0.063298  [  640/ 2636]\n",
      "loss: 0.021123  [ 1280/ 2636]\n",
      "loss: 0.062467  [ 1920/ 2636]\n",
      "loss: 0.023578  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005717\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.021246  [    0/ 2636]\n",
      "loss: 0.045731  [  640/ 2636]\n",
      "loss: 0.125763  [ 1280/ 2636]\n",
      "loss: 0.023186  [ 1920/ 2636]\n",
      "loss: 0.077053  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005426\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.096123  [    0/ 2636]\n",
      "loss: 0.070674  [  640/ 2636]\n",
      "loss: 0.084278  [ 1280/ 2636]\n",
      "loss: 0.013821  [ 1920/ 2636]\n",
      "loss: 0.032623  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.005085\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.060097  [    0/ 2636]\n",
      "loss: 0.028826  [  640/ 2636]\n",
      "loss: 0.040287  [ 1280/ 2636]\n",
      "loss: 0.038740  [ 1920/ 2636]\n",
      "loss: 0.013654  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.007399\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.010273  [    0/ 2636]\n",
      "loss: 0.046285  [  640/ 2636]\n",
      "loss: 0.031173  [ 1280/ 2636]\n",
      "loss: 0.017561  [ 1920/ 2636]\n",
      "loss: 0.015612  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 90.6%, avg loss: 0.004893\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.023654  [    0/ 2636]\n",
      "loss: 0.015104  [  640/ 2636]\n",
      "loss: 0.063724  [ 1280/ 2636]\n",
      "loss: 0.020034  [ 1920/ 2636]\n",
      "loss: 0.019291  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005378\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.021479  [    0/ 2636]\n",
      "loss: 0.017096  [  640/ 2636]\n",
      "loss: 0.032538  [ 1280/ 2636]\n",
      "loss: 0.049752  [ 1920/ 2636]\n",
      "loss: 0.020471  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.5%, avg loss: 0.006095\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.041453  [    0/ 2636]\n",
      "loss: 0.019694  [  640/ 2636]\n",
      "loss: 0.090841  [ 1280/ 2636]\n",
      "loss: 0.113486  [ 1920/ 2636]\n",
      "loss: 0.023077  [ 2560/ 2636]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.8%, avg loss: 0.005691\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:46:50.069521100Z",
     "start_time": "2023-10-13T05:13:09.426663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Resnet34_Model_2023-10-13--14-05-19.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp in the desired format\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "# Define the file name with the timestamp\n",
    "file_name = f\"Resnet34_Model_{timestamp}.pt\"\n",
    "\n",
    "# Save the entire model (including architecture and weights)\n",
    "torch.save(model, file_name)\n",
    "\n",
    "# Print the saved file name\n",
    "print(f\"Model saved as {file_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:05:19.593295400Z",
     "start_time": "2023-10-13T06:05:19.462106400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Load the model's state_dict\n",
    "model = torch.load('Resnet34_Model_2023-10-13--12-12-18.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T05:13:05.363831200Z",
     "start_time": "2023-10-13T05:13:05.148446400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming 'model' is your PyTorch model\n",
    "summary(model, input_size=(3, 64, 862))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to transform audio data into images\n",
    "def transform_data_to_image(audio, sample_rate, label, i):\n",
    "    spectrogram_tensor = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=64, n_fft=1024)(audio)[0].log2()\n",
    "    # Save the spectrogram as an image\n",
    "    image_path = f'Data/TestImages/{label}/image{i}.png'\n",
    "    plt.imsave(image_path, spectrogram_tensor.numpy(), cmap='viridis')\n",
    "    return image_path\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 862)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x[:3, :, :])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/Screaming'  # Replace with the path to your folder\n",
    "label = 'Screaming'  # Label for the images\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "predictions_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/NotScreaming'  # Replace with the path to your folder\n",
    "label = 'NotScreaming'  # Label for the images\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "predictions_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
