{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:39.504529300Z",
     "start_time": "2023-10-10T08:29:37.505546600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 2906\n    Root location: Data/Images\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 862), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n           )"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'Data/Images' #looking in subfolder train\n",
    "\n",
    "scream_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((64,862)),\n",
    "                                  transforms.ToTensor()])\n",
    ")\n",
    "scream_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:39.598313200Z",
     "start_time": "2023-10-10T08:29:39.505531300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'not_clean': 0, 'scream_clean': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=scream_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:39.604830500Z",
     "start_time": "2023-10-10T08:29:39.599313300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 2324\n",
      "Testing size: 582\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(scream_dataset))\n",
    "test_size = len(scream_dataset) - train_size\n",
    "scream_train_dataset, scream_test_dataset = torch.utils.data.random_split(scream_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(scream_train_dataset))\n",
    "print(\"Testing size:\",len(scream_test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:39.653148700Z",
     "start_time": "2023-10-10T08:29:39.604830500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 1802, 1: 522})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in scream_train_dataset]\n",
    "Counter(train_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:44.533385Z",
     "start_time": "2023-10-10T08:29:39.654149300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_test_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:44.535529200Z",
     "start_time": "2023-10-10T08:29:44.533385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.1529, 0.1882, 0.2196,  ..., 0.4667, 0.4471, 0.6863],\n         [0.1608, 0.4118, 0.3098,  ..., 0.6549, 0.5529, 0.6157],\n         [0.4863, 0.4275, 0.2196,  ..., 0.7412, 0.7176, 0.6157],\n         ...,\n         [0.1255, 0.2784, 0.2706,  ..., 0.2784, 0.2784, 0.2667],\n         [0.1255, 0.2784, 0.2784,  ..., 0.2824, 0.2784, 0.2627],\n         [0.1255, 0.2745, 0.2745,  ..., 0.2784, 0.2784, 0.2627]],\n\n        [[0.4863, 0.7059, 0.7255,  ..., 0.8157, 0.8118, 0.8627],\n         [0.6863, 0.8000, 0.7647,  ..., 0.8588, 0.8392, 0.8510],\n         [0.8235, 0.8078, 0.7255,  ..., 0.8706, 0.8667, 0.8510],\n         ...,\n         [0.5686, 0.0784, 0.0314,  ..., 0.0863, 0.0784, 0.2235],\n         [0.5686, 0.0863, 0.0588,  ..., 0.0980, 0.0863, 0.2314],\n         [0.5686, 0.0431, 0.0549,  ..., 0.0824, 0.0784, 0.2275]],\n\n        [[0.5569, 0.4784, 0.4627,  ..., 0.3216, 0.3333, 0.1804],\n         [0.4980, 0.3569, 0.4118,  ..., 0.2000, 0.2667, 0.2275],\n         [0.3098, 0.3451, 0.4627,  ..., 0.1490, 0.1608, 0.2275],\n         ...,\n         [0.5490, 0.4000, 0.3569,  ..., 0.4118, 0.4000, 0.5098],\n         [0.5490, 0.4118, 0.3843,  ..., 0.4196, 0.4118, 0.5137],\n         [0.5490, 0.3686, 0.3804,  ..., 0.4039, 0.4000, 0.5137]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = train_dataloader.dataset[0][0]\n",
    "td"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:44.615234600Z",
     "start_time": "2023-10-10T08:29:44.536529200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 862])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:44.616235400Z",
     "start_time": "2023-10-10T08:29:44.584421800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:45.814843100Z",
     "start_time": "2023-10-10T08:29:44.608233800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "import torch\n",
    "\n",
    "model = resnet34()\n",
    "model.fc = nn.Linear(512,2)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:46.909270800Z",
     "start_time": "2023-10-10T08:29:45.815845Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:29:46.925346400Z",
     "start_time": "2023-10-10T08:29:46.914272200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.194932  [    0/ 2324]\n",
      "loss: 0.187081  [  640/ 2324]\n",
      "loss: 0.231479  [ 1280/ 2324]\n",
      "loss: 0.174144  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.004248\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.182678  [    0/ 2324]\n",
      "loss: 0.385900  [  640/ 2324]\n",
      "loss: 0.361852  [ 1280/ 2324]\n",
      "loss: 0.173719  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.2%, avg loss: 0.004353\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.295594  [    0/ 2324]\n",
      "loss: 0.304038  [  640/ 2324]\n",
      "loss: 0.281105  [ 1280/ 2324]\n",
      "loss: 0.261402  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004442\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.368367  [    0/ 2324]\n",
      "loss: 0.258722  [  640/ 2324]\n",
      "loss: 0.190463  [ 1280/ 2324]\n",
      "loss: 0.394416  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004939\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.240979  [    0/ 2324]\n",
      "loss: 0.416361  [  640/ 2324]\n",
      "loss: 0.209305  [ 1280/ 2324]\n",
      "loss: 0.369274  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004817\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.340684  [    0/ 2324]\n",
      "loss: 0.322836  [  640/ 2324]\n",
      "loss: 0.228965  [ 1280/ 2324]\n",
      "loss: 0.297219  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004820\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.236772  [    0/ 2324]\n",
      "loss: 0.254243  [  640/ 2324]\n",
      "loss: 0.352607  [ 1280/ 2324]\n",
      "loss: 0.242015  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004522\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.214010  [    0/ 2324]\n",
      "loss: 0.308784  [  640/ 2324]\n",
      "loss: 0.341089  [ 1280/ 2324]\n",
      "loss: 0.318084  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004625\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.229109  [    0/ 2324]\n",
      "loss: 0.364430  [  640/ 2324]\n",
      "loss: 0.314332  [ 1280/ 2324]\n",
      "loss: 0.307644  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004482\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.283248  [    0/ 2324]\n",
      "loss: 0.238399  [  640/ 2324]\n",
      "loss: 0.238973  [ 1280/ 2324]\n",
      "loss: 0.248134  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004920\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.277840  [    0/ 2324]\n",
      "loss: 0.246351  [  640/ 2324]\n",
      "loss: 0.320548  [ 1280/ 2324]\n",
      "loss: 0.445380  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004402\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.309618  [    0/ 2324]\n",
      "loss: 0.217492  [  640/ 2324]\n",
      "loss: 0.232833  [ 1280/ 2324]\n",
      "loss: 0.283227  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004442\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.295770  [    0/ 2324]\n",
      "loss: 0.313963  [  640/ 2324]\n",
      "loss: 0.184724  [ 1280/ 2324]\n",
      "loss: 0.223673  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004442\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.293271  [    0/ 2324]\n",
      "loss: 0.344541  [  640/ 2324]\n",
      "loss: 0.312197  [ 1280/ 2324]\n",
      "loss: 0.374870  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004353\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.359147  [    0/ 2324]\n",
      "loss: 0.296699  [  640/ 2324]\n",
      "loss: 0.263057  [ 1280/ 2324]\n",
      "loss: 0.294135  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 88.8%, avg loss: 0.004345\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.254759  [    0/ 2324]\n",
      "loss: 0.302648  [  640/ 2324]\n",
      "loss: 0.286244  [ 1280/ 2324]\n",
      "loss: 0.260346  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004660\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.446869  [    0/ 2324]\n",
      "loss: 0.209080  [  640/ 2324]\n",
      "loss: 0.347037  [ 1280/ 2324]\n",
      "loss: 0.256833  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004318\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.228921  [    0/ 2324]\n",
      "loss: 0.246188  [  640/ 2324]\n",
      "loss: 0.265413  [ 1280/ 2324]\n",
      "loss: 0.486728  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.004250\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.409986  [    0/ 2324]\n",
      "loss: 0.294806  [  640/ 2324]\n",
      "loss: 0.283276  [ 1280/ 2324]\n",
      "loss: 0.240063  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004787\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.276563  [    0/ 2324]\n",
      "loss: 0.209659  [  640/ 2324]\n",
      "loss: 0.249774  [ 1280/ 2324]\n",
      "loss: 0.185540  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004337\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.194942  [    0/ 2324]\n",
      "loss: 0.419358  [  640/ 2324]\n",
      "loss: 0.220521  [ 1280/ 2324]\n",
      "loss: 0.291474  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004343\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.307976  [    0/ 2324]\n",
      "loss: 0.265944  [  640/ 2324]\n",
      "loss: 0.298617  [ 1280/ 2324]\n",
      "loss: 0.334363  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004498\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.240913  [    0/ 2324]\n",
      "loss: 0.266430  [  640/ 2324]\n",
      "loss: 0.282491  [ 1280/ 2324]\n",
      "loss: 0.295168  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.005226\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.347931  [    0/ 2324]\n",
      "loss: 0.248047  [  640/ 2324]\n",
      "loss: 0.301783  [ 1280/ 2324]\n",
      "loss: 0.221658  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 90.0%, avg loss: 0.004596\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.403943  [    0/ 2324]\n",
      "loss: 0.376751  [  640/ 2324]\n",
      "loss: 0.363684  [ 1280/ 2324]\n",
      "loss: 0.355886  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004379\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.281530  [    0/ 2324]\n",
      "loss: 0.383913  [  640/ 2324]\n",
      "loss: 0.211991  [ 1280/ 2324]\n",
      "loss: 0.317812  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004422\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.220247  [    0/ 2324]\n",
      "loss: 0.201381  [  640/ 2324]\n",
      "loss: 0.284729  [ 1280/ 2324]\n",
      "loss: 0.233696  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 88.7%, avg loss: 0.004719\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.241650  [    0/ 2324]\n",
      "loss: 0.305658  [  640/ 2324]\n",
      "loss: 0.317263  [ 1280/ 2324]\n",
      "loss: 0.215861  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004382\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.199988  [    0/ 2324]\n",
      "loss: 0.290104  [  640/ 2324]\n",
      "loss: 0.368654  [ 1280/ 2324]\n",
      "loss: 0.315474  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004727\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.222784  [    0/ 2324]\n",
      "loss: 0.280232  [  640/ 2324]\n",
      "loss: 0.406938  [ 1280/ 2324]\n",
      "loss: 0.249986  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.004264\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.296134  [    0/ 2324]\n",
      "loss: 0.304612  [  640/ 2324]\n",
      "loss: 0.202236  [ 1280/ 2324]\n",
      "loss: 0.216439  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.005735\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.392946  [    0/ 2324]\n",
      "loss: 0.220719  [  640/ 2324]\n",
      "loss: 0.278560  [ 1280/ 2324]\n",
      "loss: 0.276808  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004875\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.309336  [    0/ 2324]\n",
      "loss: 0.271034  [  640/ 2324]\n",
      "loss: 0.239723  [ 1280/ 2324]\n",
      "loss: 0.277162  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.0%, avg loss: 0.004945\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.205818  [    0/ 2324]\n",
      "loss: 0.431750  [  640/ 2324]\n",
      "loss: 0.264969  [ 1280/ 2324]\n",
      "loss: 0.257524  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004306\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.210214  [    0/ 2324]\n",
      "loss: 0.259900  [  640/ 2324]\n",
      "loss: 0.361681  [ 1280/ 2324]\n",
      "loss: 0.255432  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004984\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.301003  [    0/ 2324]\n",
      "loss: 0.328543  [  640/ 2324]\n",
      "loss: 0.180424  [ 1280/ 2324]\n",
      "loss: 0.200697  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004890\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.351507  [    0/ 2324]\n",
      "loss: 0.487786  [  640/ 2324]\n",
      "loss: 0.195359  [ 1280/ 2324]\n",
      "loss: 0.255140  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004759\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.249088  [    0/ 2324]\n",
      "loss: 0.292127  [  640/ 2324]\n",
      "loss: 0.210454  [ 1280/ 2324]\n",
      "loss: 0.272470  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.004910\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.280552  [    0/ 2324]\n",
      "loss: 0.308119  [  640/ 2324]\n",
      "loss: 0.391703  [ 1280/ 2324]\n",
      "loss: 0.231972  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004425\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.404732  [    0/ 2324]\n",
      "loss: 0.206645  [  640/ 2324]\n",
      "loss: 0.328115  [ 1280/ 2324]\n",
      "loss: 0.212633  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004290\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.484510  [    0/ 2324]\n",
      "loss: 0.346105  [  640/ 2324]\n",
      "loss: 0.445091  [ 1280/ 2324]\n",
      "loss: 0.233051  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.5%, avg loss: 0.004442\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.311838  [    0/ 2324]\n",
      "loss: 0.211108  [  640/ 2324]\n",
      "loss: 0.263367  [ 1280/ 2324]\n",
      "loss: 0.272268  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004553\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.292636  [    0/ 2324]\n",
      "loss: 0.393122  [  640/ 2324]\n",
      "loss: 0.262309  [ 1280/ 2324]\n",
      "loss: 0.302772  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 88.8%, avg loss: 0.004335\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.184519  [    0/ 2324]\n",
      "loss: 0.207935  [  640/ 2324]\n",
      "loss: 0.325002  [ 1280/ 2324]\n",
      "loss: 0.384145  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.0%, avg loss: 0.004436\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.350087  [    0/ 2324]\n",
      "loss: 0.274558  [  640/ 2324]\n",
      "loss: 0.303121  [ 1280/ 2324]\n",
      "loss: 0.175323  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004545\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.435243  [    0/ 2324]\n",
      "loss: 0.324825  [  640/ 2324]\n",
      "loss: 0.238164  [ 1280/ 2324]\n",
      "loss: 0.215781  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.005108\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.349445  [    0/ 2324]\n",
      "loss: 0.225158  [  640/ 2324]\n",
      "loss: 0.287869  [ 1280/ 2324]\n",
      "loss: 0.340666  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.004449\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.339499  [    0/ 2324]\n",
      "loss: 0.307333  [  640/ 2324]\n",
      "loss: 0.219220  [ 1280/ 2324]\n",
      "loss: 0.367739  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 90.0%, avg loss: 0.004223\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.268216  [    0/ 2324]\n",
      "loss: 0.347484  [  640/ 2324]\n",
      "loss: 0.223238  [ 1280/ 2324]\n",
      "loss: 0.239930  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004404\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.232707  [    0/ 2324]\n",
      "loss: 0.258618  [  640/ 2324]\n",
      "loss: 0.334575  [ 1280/ 2324]\n",
      "loss: 0.275351  [ 1920/ 2324]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.004748\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:02:01.122954800Z",
     "start_time": "2023-10-10T08:46:02.960654200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model_2023-10-10--17-02-06.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp in the desired format\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "# Define the file name with the timestamp\n",
    "file_name = f\"model_{timestamp}.pt\"\n",
    "\n",
    "# Save the entire model (including architecture and weights)\n",
    "torch.save(model, file_name)\n",
    "\n",
    "# Print the saved file name\n",
    "print(f\"Model saved as {file_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:02:07.121584Z",
     "start_time": "2023-10-10T09:02:06.972147500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Load the model's state_dict\n",
    "model = torch.load('model_2023-10-10--17-02-06.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:02:38.841483100Z",
     "start_time": "2023-10-10T09:02:38.667714100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 32, 431]           9,408\n",
      "       BatchNorm2d-2          [-1, 64, 32, 431]             128\n",
      "              ReLU-3          [-1, 64, 32, 431]               0\n",
      "         MaxPool2d-4          [-1, 64, 16, 216]               0\n",
      "            Conv2d-5          [-1, 64, 16, 216]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 16, 216]             128\n",
      "              ReLU-7          [-1, 64, 16, 216]               0\n",
      "            Conv2d-8          [-1, 64, 16, 216]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 16, 216]             128\n",
      "             ReLU-10          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-11          [-1, 64, 16, 216]               0\n",
      "           Conv2d-12          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 16, 216]             128\n",
      "             ReLU-14          [-1, 64, 16, 216]               0\n",
      "           Conv2d-15          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 16, 216]             128\n",
      "             ReLU-17          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-18          [-1, 64, 16, 216]               0\n",
      "           Conv2d-19          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-20          [-1, 64, 16, 216]             128\n",
      "             ReLU-21          [-1, 64, 16, 216]               0\n",
      "           Conv2d-22          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-23          [-1, 64, 16, 216]             128\n",
      "             ReLU-24          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-25          [-1, 64, 16, 216]               0\n",
      "           Conv2d-26          [-1, 128, 8, 108]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 8, 108]             256\n",
      "             ReLU-28          [-1, 128, 8, 108]               0\n",
      "           Conv2d-29          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 8, 108]             256\n",
      "           Conv2d-31          [-1, 128, 8, 108]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 8, 108]             256\n",
      "             ReLU-33          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-34          [-1, 128, 8, 108]               0\n",
      "           Conv2d-35          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 8, 108]             256\n",
      "             ReLU-37          [-1, 128, 8, 108]               0\n",
      "           Conv2d-38          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 8, 108]             256\n",
      "             ReLU-40          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-41          [-1, 128, 8, 108]               0\n",
      "           Conv2d-42          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 8, 108]             256\n",
      "             ReLU-44          [-1, 128, 8, 108]               0\n",
      "           Conv2d-45          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 8, 108]             256\n",
      "             ReLU-47          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-48          [-1, 128, 8, 108]               0\n",
      "           Conv2d-49          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 8, 108]             256\n",
      "             ReLU-51          [-1, 128, 8, 108]               0\n",
      "           Conv2d-52          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 8, 108]             256\n",
      "             ReLU-54          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-55          [-1, 128, 8, 108]               0\n",
      "           Conv2d-56           [-1, 256, 4, 54]         294,912\n",
      "      BatchNorm2d-57           [-1, 256, 4, 54]             512\n",
      "             ReLU-58           [-1, 256, 4, 54]               0\n",
      "           Conv2d-59           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-60           [-1, 256, 4, 54]             512\n",
      "           Conv2d-61           [-1, 256, 4, 54]          32,768\n",
      "      BatchNorm2d-62           [-1, 256, 4, 54]             512\n",
      "             ReLU-63           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-64           [-1, 256, 4, 54]               0\n",
      "           Conv2d-65           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-66           [-1, 256, 4, 54]             512\n",
      "             ReLU-67           [-1, 256, 4, 54]               0\n",
      "           Conv2d-68           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-69           [-1, 256, 4, 54]             512\n",
      "             ReLU-70           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-71           [-1, 256, 4, 54]               0\n",
      "           Conv2d-72           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-73           [-1, 256, 4, 54]             512\n",
      "             ReLU-74           [-1, 256, 4, 54]               0\n",
      "           Conv2d-75           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-76           [-1, 256, 4, 54]             512\n",
      "             ReLU-77           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-78           [-1, 256, 4, 54]               0\n",
      "           Conv2d-79           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-80           [-1, 256, 4, 54]             512\n",
      "             ReLU-81           [-1, 256, 4, 54]               0\n",
      "           Conv2d-82           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-83           [-1, 256, 4, 54]             512\n",
      "             ReLU-84           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-85           [-1, 256, 4, 54]               0\n",
      "           Conv2d-86           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-87           [-1, 256, 4, 54]             512\n",
      "             ReLU-88           [-1, 256, 4, 54]               0\n",
      "           Conv2d-89           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-90           [-1, 256, 4, 54]             512\n",
      "             ReLU-91           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-92           [-1, 256, 4, 54]               0\n",
      "           Conv2d-93           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-94           [-1, 256, 4, 54]             512\n",
      "             ReLU-95           [-1, 256, 4, 54]               0\n",
      "           Conv2d-96           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-97           [-1, 256, 4, 54]             512\n",
      "             ReLU-98           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-99           [-1, 256, 4, 54]               0\n",
      "          Conv2d-100           [-1, 512, 2, 27]       1,179,648\n",
      "     BatchNorm2d-101           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-102           [-1, 512, 2, 27]               0\n",
      "          Conv2d-103           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-104           [-1, 512, 2, 27]           1,024\n",
      "          Conv2d-105           [-1, 512, 2, 27]         131,072\n",
      "     BatchNorm2d-106           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-107           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-108           [-1, 512, 2, 27]               0\n",
      "          Conv2d-109           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-110           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-111           [-1, 512, 2, 27]               0\n",
      "          Conv2d-112           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-113           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-114           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-115           [-1, 512, 2, 27]               0\n",
      "          Conv2d-116           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-117           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-118           [-1, 512, 2, 27]               0\n",
      "          Conv2d-119           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-120           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-121           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-122           [-1, 512, 2, 27]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.63\n",
      "Forward/backward pass size (MB): 106.06\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 187.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming 'model' is your PyTorch model\n",
    "summary(model, input_size=(3, 64, 862))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:02:40.231052200Z",
     "start_time": "2023-10-10T09:02:40.188175800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to transform audio data into images\n",
    "def transform_data_to_image(audio, sample_rate, label, i):\n",
    "    spectrogram_tensor = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=64, n_fft=1024)(audio)[0].log2()\n",
    "    # Save the spectrogram as an image\n",
    "    image_path = f'Data/TestImages/{label}/image{i}.png'\n",
    "    plt.imsave(image_path, spectrogram_tensor.numpy(), cmap='viridis')\n",
    "    return image_path\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 862)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x[:3, :, :])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:02:41.943696200Z",
     "start_time": "2023-10-10T09:02:41.935199500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:1354: RuntimeWarning: invalid value encountered in subtract\n",
      "  resdat -= vmin\n",
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:1355: RuntimeWarning: invalid value encountered in divide\n",
      "  resdat /= (vmax - vmin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                Filename  Prediction\n0    ---1_cCGK4M_out.wav           0\n1    -20uudT97E0_out.wav           0\n2    -2yygHLdpXc_out.wav           0\n3    -3bGlOhRkAo_out.wav           1\n4    -4pUrlMafww_out.wav           1\n..                   ...         ...\n857  _QMEw67gWIA_out.wav           0\n858  _TLzbbay6Hw_out.wav           0\n859  _XPPISqmXSE_out.wav           0\n860  _xRpsu02t9o_out.wav           1\n861  _zzhHu7HwZc_out.wav           0\n\n[862 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>---1_cCGK4M_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-20uudT97E0_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2yygHLdpXc_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-3bGlOhRkAo_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-4pUrlMafww_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>_QMEw67gWIA_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>_TLzbbay6Hw_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>859</th>\n      <td>_XPPISqmXSE_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>_xRpsu02t9o_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>_zzhHu7HwZc_out.wav</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>862 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/Screaming'  # Replace with the path to your folder\n",
    "label = 'Screaming'  # Label for the images\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "predictions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:12:07.038303800Z",
     "start_time": "2023-10-10T09:11:18.503749400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Prediction\n1    445\n0    417\nName: count, dtype: int64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:12:59.340995600Z",
     "start_time": "2023-10-10T09:12:59.329822700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:1354: RuntimeWarning: invalid value encountered in subtract\n",
      "  resdat -= vmin\n",
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:1355: RuntimeWarning: invalid value encountered in divide\n",
      "  resdat /= (vmax - vmin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Filename  Prediction\n0     --PJHxphWEs_out.wav           0\n1     -28U1_qW0sU_out.wav           0\n2     -4xJv59_zcA_out.wav           0\n3     -5GhUbDLYkQ_out.wav           1\n4     -5Jlimvsuwo_out.wav           0\n...                   ...         ...\n2094  _XusTa2prSw_out.wav           0\n2095  _y07ENAx2_E_out.wav           0\n2096  _yqlQimkHpQ_out.wav           0\n2097  _Zsk5Fxqbkc_out.wav           0\n2098  __qxgIqI0uA_out.wav           0\n\n[2099 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>--PJHxphWEs_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-28U1_qW0sU_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-4xJv59_zcA_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-5GhUbDLYkQ_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-5Jlimvsuwo_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2094</th>\n      <td>_XusTa2prSw_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>_y07ENAx2_E_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>_yqlQimkHpQ_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>_Zsk5Fxqbkc_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>__qxgIqI0uA_out.wav</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2099 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/NotScreaming'  # Replace with the path to your folder\n",
    "label = 'NotScreaming'  # Label for the images\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "predictions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:22:01.274762Z",
     "start_time": "2023-10-10T09:19:39.937738300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Prediction\n0    2012\n1      87\nName: count, dtype: int64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T09:22:19.916376600Z",
     "start_time": "2023-10-10T09:22:19.895055300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
