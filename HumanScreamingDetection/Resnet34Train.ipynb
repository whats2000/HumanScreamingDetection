{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:59:43.226838100Z",
     "start_time": "2023-10-13T08:59:41.280014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 3544\n    Root location: Data/Images\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 862), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n           )"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'Data/Images' #looking in subfolder train\n",
    "\n",
    "scream_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((64,862)),\n",
    "                                  transforms.ToTensor()])\n",
    ")\n",
    "scream_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:59:45.818959400Z",
     "start_time": "2023-10-13T08:59:45.777401300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'not': 0, 'scream': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=scream_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:59:47.881782400Z",
     "start_time": "2023-10-13T08:59:47.879261700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 2835\n",
      "Testing size: 709\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(scream_dataset))\n",
    "test_size = len(scream_dataset) - train_size\n",
    "scream_train_dataset, scream_test_dataset = torch.utils.data.random_split(scream_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(scream_train_dataset))\n",
    "print(\"Testing size:\",len(scream_test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:59:49.172153700Z",
     "start_time": "2023-10-13T08:59:49.161497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 2082, 1: 753})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in scream_train_dataset]\n",
    "Counter(train_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:59:56.732193300Z",
     "start_time": "2023-10-13T08:59:50.789225700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    scream_test_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:05.887082400Z",
     "start_time": "2023-10-13T09:00:05.880077300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.2000, 0.6471, 0.5137,  ..., 0.8118, 0.8118, 0.7490],\n         [0.7294, 0.7294, 0.5843,  ..., 0.8314, 0.8235, 0.6980],\n         [0.6235, 0.7725, 0.6353,  ..., 0.8039, 0.8039, 0.6784],\n         ...,\n         [0.1569, 0.2824, 0.2784,  ..., 0.2824, 0.2824, 0.1569],\n         [0.1569, 0.2824, 0.2824,  ..., 0.2824, 0.2824, 0.1569],\n         [0.1569, 0.2784, 0.2784,  ..., 0.2784, 0.2745, 0.1569]],\n\n        [[0.7137, 0.8549, 0.8275,  ..., 0.8824, 0.8824, 0.8745],\n         [0.8706, 0.8706, 0.8431,  ..., 0.8824, 0.8824, 0.8667],\n         [0.8510, 0.8745, 0.8549,  ..., 0.8784, 0.8784, 0.8627],\n         ...,\n         [0.4824, 0.1098, 0.1529,  ..., 0.1176, 0.1255, 0.4784],\n         [0.4784, 0.1255, 0.1294,  ..., 0.1255, 0.1176, 0.4784],\n         [0.4784, 0.0588, 0.0667,  ..., 0.0824, 0.0549, 0.4784]],\n\n        [[0.4745, 0.2078, 0.2941,  ..., 0.1098, 0.1098, 0.1412],\n         [0.1529, 0.1529, 0.2471,  ..., 0.1020, 0.1059, 0.1725],\n         [0.2196, 0.1294, 0.2157,  ..., 0.1137, 0.1137, 0.1882],\n         ...,\n         [0.5569, 0.4314, 0.4667,  ..., 0.4392, 0.4431, 0.5569],\n         [0.5569, 0.4431, 0.4471,  ..., 0.4431, 0.4392, 0.5569],\n         [0.5569, 0.3843, 0.3882,  ..., 0.4039, 0.3804, 0.5569]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = train_dataloader.dataset[0][0]\n",
    "td"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:07.096033700Z",
     "start_time": "2023-10-13T09:00:07.082054600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 862])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:08.179083400Z",
     "start_time": "2023-10-13T09:00:08.149833300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:10.292660800Z",
     "start_time": "2023-10-13T09:00:10.289612800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet34\n",
    "import torch\n",
    "\n",
    "model = resnet34(pretrained=True)\n",
    "model.fc = nn.Linear(512,2)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:12.596095500Z",
     "start_time": "2023-10-13T09:00:11.492642300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0  # Counter for correct predictions\n",
    "    total = 0  # Counter for total examples\n",
    "\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = pred.max(1)\n",
    "        total += Y.size(0)\n",
    "        correct += predicted.eq(Y).sum().item()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]  Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')\n",
    "    return test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:00:24.570162900Z",
     "start_time": "2023-10-13T09:00:24.563867200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.617827  [    0/ 2835]  Train Accuracy: 65.62%\n",
      "loss: 0.576579  [  640/ 2835]  Train Accuracy: 76.28%\n",
      "loss: 0.443220  [ 1280/ 2835]  Train Accuracy: 77.68%\n",
      "loss: 0.404635  [ 1920/ 2835]  Train Accuracy: 79.18%\n",
      "loss: 0.429366  [ 2560/ 2835]  Train Accuracy: 79.27%\n",
      "\n",
      "Test Error:\n",
      "acc: 86.2%, avg loss: 0.006457\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.334044  [    0/ 2835]  Train Accuracy: 85.94%\n",
      "loss: 0.307825  [  640/ 2835]  Train Accuracy: 83.24%\n",
      "loss: 0.300307  [ 1280/ 2835]  Train Accuracy: 83.48%\n",
      "loss: 0.567328  [ 1920/ 2835]  Train Accuracy: 83.72%\n",
      "loss: 0.259164  [ 2560/ 2835]  Train Accuracy: 84.87%\n",
      "\n",
      "Test Error:\n",
      "acc: 86.9%, avg loss: 0.005303\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.271759  [    0/ 2835]  Train Accuracy: 89.06%\n",
      "loss: 0.457978  [  640/ 2835]  Train Accuracy: 87.50%\n",
      "loss: 0.359004  [ 1280/ 2835]  Train Accuracy: 86.53%\n",
      "loss: 0.338054  [ 1920/ 2835]  Train Accuracy: 86.44%\n",
      "loss: 0.360473  [ 2560/ 2835]  Train Accuracy: 86.24%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.9%, avg loss: 0.006079\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.344699  [    0/ 2835]  Train Accuracy: 87.50%\n",
      "loss: 0.343178  [  640/ 2835]  Train Accuracy: 86.79%\n",
      "loss: 0.283449  [ 1280/ 2835]  Train Accuracy: 86.76%\n",
      "loss: 0.300695  [ 1920/ 2835]  Train Accuracy: 86.74%\n",
      "loss: 0.248007  [ 2560/ 2835]  Train Accuracy: 86.70%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.0%, avg loss: 0.006336\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.297152  [    0/ 2835]  Train Accuracy: 87.50%\n",
      "loss: 0.188919  [  640/ 2835]  Train Accuracy: 87.93%\n",
      "loss: 0.203902  [ 1280/ 2835]  Train Accuracy: 88.47%\n",
      "loss: 0.264056  [ 1920/ 2835]  Train Accuracy: 88.66%\n",
      "loss: 0.275447  [ 2560/ 2835]  Train Accuracy: 88.49%\n",
      "\n",
      "Test Error:\n",
      "acc: 88.6%, avg loss: 0.005229\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.280258  [    0/ 2835]  Train Accuracy: 87.50%\n",
      "loss: 0.249784  [  640/ 2835]  Train Accuracy: 89.91%\n",
      "loss: 0.213449  [ 1280/ 2835]  Train Accuracy: 89.58%\n",
      "loss: 0.156841  [ 1920/ 2835]  Train Accuracy: 89.57%\n",
      "loss: 0.228702  [ 2560/ 2835]  Train Accuracy: 89.56%\n",
      "\n",
      "Test Error:\n",
      "acc: 84.9%, avg loss: 0.006145\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.179895  [    0/ 2835]  Train Accuracy: 92.19%\n",
      "loss: 0.341809  [  640/ 2835]  Train Accuracy: 87.22%\n",
      "loss: 0.317986  [ 1280/ 2835]  Train Accuracy: 87.50%\n",
      "loss: 0.303786  [ 1920/ 2835]  Train Accuracy: 88.76%\n",
      "loss: 0.392025  [ 2560/ 2835]  Train Accuracy: 88.61%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.3%, avg loss: 0.005829\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.226665  [    0/ 2835]  Train Accuracy: 90.62%\n",
      "loss: 0.263699  [  640/ 2835]  Train Accuracy: 91.62%\n",
      "loss: 0.175003  [ 1280/ 2835]  Train Accuracy: 91.22%\n",
      "loss: 0.293955  [ 1920/ 2835]  Train Accuracy: 90.83%\n",
      "loss: 0.236641  [ 2560/ 2835]  Train Accuracy: 90.93%\n",
      "\n",
      "Test Error:\n",
      "acc: 81.9%, avg loss: 0.010515\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.227695  [    0/ 2835]  Train Accuracy: 90.62%\n",
      "loss: 0.230601  [  640/ 2835]  Train Accuracy: 92.05%\n",
      "loss: 0.236412  [ 1280/ 2835]  Train Accuracy: 91.74%\n",
      "loss: 0.191967  [ 1920/ 2835]  Train Accuracy: 91.83%\n",
      "loss: 0.207109  [ 2560/ 2835]  Train Accuracy: 91.16%\n",
      "\n",
      "Test Error:\n",
      "acc: 76.7%, avg loss: 0.012014\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.217744  [    0/ 2835]  Train Accuracy: 93.75%\n",
      "loss: 0.216220  [  640/ 2835]  Train Accuracy: 92.61%\n",
      "loss: 0.319631  [ 1280/ 2835]  Train Accuracy: 92.26%\n",
      "loss: 0.157282  [ 1920/ 2835]  Train Accuracy: 92.49%\n",
      "loss: 0.140968  [ 2560/ 2835]  Train Accuracy: 92.34%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.3%, avg loss: 0.007103\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.146743  [    0/ 2835]  Train Accuracy: 95.31%\n",
      "loss: 0.169532  [  640/ 2835]  Train Accuracy: 92.76%\n",
      "loss: 0.086705  [ 1280/ 2835]  Train Accuracy: 93.53%\n",
      "loss: 0.149642  [ 1920/ 2835]  Train Accuracy: 93.60%\n",
      "loss: 0.171405  [ 2560/ 2835]  Train Accuracy: 93.52%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.5%, avg loss: 0.006495\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.169793  [    0/ 2835]  Train Accuracy: 93.75%\n",
      "loss: 0.173124  [  640/ 2835]  Train Accuracy: 94.03%\n",
      "loss: 0.229269  [ 1280/ 2835]  Train Accuracy: 93.08%\n",
      "loss: 0.188056  [ 1920/ 2835]  Train Accuracy: 92.34%\n",
      "loss: 0.162453  [ 2560/ 2835]  Train Accuracy: 92.45%\n",
      "\n",
      "Test Error:\n",
      "acc: 89.4%, avg loss: 0.005033\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.101805  [    0/ 2835]  Train Accuracy: 95.31%\n",
      "loss: 0.114980  [  640/ 2835]  Train Accuracy: 96.02%\n",
      "loss: 0.131102  [ 1280/ 2835]  Train Accuracy: 95.91%\n",
      "loss: 0.166705  [ 1920/ 2835]  Train Accuracy: 94.61%\n",
      "loss: 0.255655  [ 2560/ 2835]  Train Accuracy: 94.05%\n",
      "\n",
      "Test Error:\n",
      "acc: 84.9%, avg loss: 0.044194\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.113804  [    0/ 2835]  Train Accuracy: 96.88%\n",
      "loss: 0.208349  [  640/ 2835]  Train Accuracy: 91.05%\n",
      "loss: 0.264423  [ 1280/ 2835]  Train Accuracy: 91.07%\n",
      "loss: 0.238608  [ 1920/ 2835]  Train Accuracy: 91.99%\n",
      "loss: 0.081829  [ 2560/ 2835]  Train Accuracy: 92.42%\n",
      "\n",
      "Test Error:\n",
      "acc: 86.2%, avg loss: 0.006154\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.137811  [    0/ 2835]  Train Accuracy: 95.31%\n",
      "loss: 0.148079  [  640/ 2835]  Train Accuracy: 94.89%\n",
      "loss: 0.141671  [ 1280/ 2835]  Train Accuracy: 95.61%\n",
      "loss: 0.278170  [ 1920/ 2835]  Train Accuracy: 94.91%\n",
      "loss: 0.091196  [ 2560/ 2835]  Train Accuracy: 94.82%\n",
      "\n",
      "Test Error:\n",
      "acc: 89.1%, avg loss: 0.005824\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.157355  [    0/ 2835]  Train Accuracy: 93.75%\n",
      "loss: 0.134452  [  640/ 2835]  Train Accuracy: 94.60%\n",
      "loss: 0.107705  [ 1280/ 2835]  Train Accuracy: 95.46%\n",
      "loss: 0.105619  [ 1920/ 2835]  Train Accuracy: 95.16%\n",
      "loss: 0.147578  [ 2560/ 2835]  Train Accuracy: 94.59%\n",
      "\n",
      "Test Error:\n",
      "acc: 87.4%, avg loss: 0.005934\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.150772  [    0/ 2835]  Train Accuracy: 93.75%\n",
      "loss: 0.171869  [  640/ 2835]  Train Accuracy: 93.32%\n",
      "loss: 0.129031  [ 1280/ 2835]  Train Accuracy: 94.42%\n",
      "loss: 0.089336  [ 1920/ 2835]  Train Accuracy: 94.61%\n",
      "loss: 0.075926  [ 2560/ 2835]  Train Accuracy: 94.74%\n",
      "\n",
      "Test Error:\n",
      "acc: 87.0%, avg loss: 0.006028\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.131379  [    0/ 2835]  Train Accuracy: 96.88%\n",
      "loss: 0.148759  [  640/ 2835]  Train Accuracy: 96.59%\n",
      "loss: 0.059832  [ 1280/ 2835]  Train Accuracy: 96.80%\n",
      "loss: 0.063734  [ 1920/ 2835]  Train Accuracy: 95.92%\n",
      "loss: 0.119062  [ 2560/ 2835]  Train Accuracy: 96.30%\n",
      "\n",
      "Test Error:\n",
      "acc: 86.3%, avg loss: 0.011089\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.022248  [    0/ 2835]  Train Accuracy: 100.00%\n",
      "loss: 0.114953  [  640/ 2835]  Train Accuracy: 95.60%\n",
      "loss: 0.098934  [ 1280/ 2835]  Train Accuracy: 95.91%\n",
      "loss: 0.126424  [ 1920/ 2835]  Train Accuracy: 95.61%\n",
      "loss: 0.077435  [ 2560/ 2835]  Train Accuracy: 95.73%\n",
      "\n",
      "Test Error:\n",
      "acc: 85.0%, avg loss: 0.008243\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.083508  [    0/ 2835]  Train Accuracy: 96.88%\n",
      "loss: 0.339770  [  640/ 2835]  Train Accuracy: 92.76%\n",
      "loss: 0.128116  [ 1280/ 2835]  Train Accuracy: 93.68%\n",
      "loss: 0.073510  [ 1920/ 2835]  Train Accuracy: 94.25%\n",
      "loss: 0.158975  [ 2560/ 2835]  Train Accuracy: 94.47%\n",
      "\n",
      "Test Error:\n",
      "acc: 86.5%, avg loss: 0.009009\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.042581  [    0/ 2835]  Train Accuracy: 100.00%\n",
      "loss: 0.129313  [  640/ 2835]  Train Accuracy: 98.72%\n",
      "loss: 0.089291  [ 1280/ 2835]  Train Accuracy: 97.47%\n",
      "loss: 0.132654  [ 1920/ 2835]  Train Accuracy: 96.57%\n",
      "loss: 0.167397  [ 2560/ 2835]  Train Accuracy: 96.27%\n",
      "\n",
      "Test Error:\n",
      "acc: 84.2%, avg loss: 0.009015\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.028672  [    0/ 2835]  Train Accuracy: 100.00%\n",
      "loss: 0.138118  [  640/ 2835]  Train Accuracy: 97.02%\n",
      "loss: 0.079389  [ 1280/ 2835]  Train Accuracy: 97.17%\n",
      "loss: 0.013822  [ 1920/ 2835]  Train Accuracy: 97.28%\n",
      "loss: 0.086707  [ 2560/ 2835]  Train Accuracy: 97.48%\n",
      "\n",
      "Test Error:\n",
      "acc: 89.4%, avg loss: 0.007915\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.055494  [    0/ 2835]  Train Accuracy: 96.88%\n",
      "loss: 0.146774  [  640/ 2835]  Train Accuracy: 98.01%\n",
      "loss: 0.037373  [ 1280/ 2835]  Train Accuracy: 98.36%\n",
      "loss: 0.133705  [ 1920/ 2835]  Train Accuracy: 98.34%\n",
      "loss: 0.017119  [ 2560/ 2835]  Train Accuracy: 98.21%\n",
      "\n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.009234\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.017918  [    0/ 2835]  Train Accuracy: 100.00%\n",
      "loss: 0.055729  [  640/ 2835]  Train Accuracy: 95.45%\n",
      "loss: 0.158255  [ 1280/ 2835]  Train Accuracy: 94.49%\n",
      "loss: 0.223178  [ 1920/ 2835]  Train Accuracy: 93.95%\n",
      "loss: 0.189619  [ 2560/ 2835]  Train Accuracy: 93.94%\n",
      "\n",
      "Test Error:\n",
      "acc: 88.6%, avg loss: 0.005836\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.051250  [    0/ 2835]  Train Accuracy: 98.44%\n",
      "loss: 0.044262  [  640/ 2835]  Train Accuracy: 97.30%\n",
      "loss: 0.025385  [ 1280/ 2835]  Train Accuracy: 97.32%\n",
      "loss: 0.013686  [ 1920/ 2835]  Train Accuracy: 97.28%\n",
      "loss: 0.026015  [ 2560/ 2835]  Train Accuracy: 97.41%\n",
      "\n",
      "Test Error:\n",
      "acc: 87.9%, avg loss: 0.008457\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.046439  [    0/ 2835]  Train Accuracy: 98.44%\n",
      "loss: 0.068196  [  640/ 2835]  Train Accuracy: 98.01%\n",
      "loss: 0.077359  [ 1280/ 2835]  Train Accuracy: 98.66%\n",
      "loss: 0.053010  [ 1920/ 2835]  Train Accuracy: 98.69%\n",
      "loss: 0.050712  [ 2560/ 2835]  Train Accuracy: 98.67%\n",
      "\n",
      "Test Error:\n",
      "acc: 88.4%, avg loss: 0.008126\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.024926  [    0/ 2835]  Train Accuracy: 100.00%\n",
      "loss: 0.052318  [  640/ 2835]  Train Accuracy: 98.44%\n",
      "loss: 0.040948  [ 1280/ 2835]  Train Accuracy: 97.99%\n",
      "loss: 0.018991  [ 1920/ 2835]  Train Accuracy: 97.58%\n",
      "loss: 0.061149  [ 2560/ 2835]  Train Accuracy: 97.60%\n",
      "\n",
      "Test Error:\n",
      "acc: 88.0%, avg loss: 0.007340\n",
      "\n",
      "Early stopping triggered. No improvement in test loss for 15 epochs.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define the early stopping parameters\n",
    "early_stopping_patience = 15  # Number of epochs to wait before early stopping\n",
    "best_loss = torch.inf\n",
    "wait = 0  # Counter for patience\n",
    "epochs = 150\n",
    "\n",
    "best_model_weights = None\n",
    "\n",
    "# Training loop\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test_loss = test(test_dataloader, model)\n",
    "\n",
    "    # Check if the test loss has improved\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        wait = 0  # Reset patience\n",
    "\n",
    "        # Save the best model weights\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    if wait >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered. No improvement in test loss for {} epochs.\".format(early_stopping_patience))\n",
    "        break  # Stop training\n",
    "\n",
    "# Restore the best model weights\n",
    "if best_model_weights is not None:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:10:29.582818900Z",
     "start_time": "2023-10-13T09:00:25.471098100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Resnet34_Model_2023-10-13--17-11-18.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp in the desired format\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "# Define the file name with the timestamp\n",
    "file_name = f\"Resnet34_Model_{timestamp}.pt\"\n",
    "\n",
    "# Save the entire model (including architecture and weights)\n",
    "torch.save(model, file_name)\n",
    "\n",
    "# Print the saved file name\n",
    "print(f\"Model saved as {file_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:11:18.569231100Z",
     "start_time": "2023-10-13T09:11:18.443005700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Load the model's state_dict\n",
    "model = torch.load('Resnet34_Model_2023-10-13--17-11-18.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:11:50.235876200Z",
     "start_time": "2023-10-13T09:11:50.067489600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 32, 431]           9,408\n",
      "       BatchNorm2d-2          [-1, 64, 32, 431]             128\n",
      "              ReLU-3          [-1, 64, 32, 431]               0\n",
      "         MaxPool2d-4          [-1, 64, 16, 216]               0\n",
      "            Conv2d-5          [-1, 64, 16, 216]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 16, 216]             128\n",
      "              ReLU-7          [-1, 64, 16, 216]               0\n",
      "            Conv2d-8          [-1, 64, 16, 216]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 16, 216]             128\n",
      "             ReLU-10          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-11          [-1, 64, 16, 216]               0\n",
      "           Conv2d-12          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 16, 216]             128\n",
      "             ReLU-14          [-1, 64, 16, 216]               0\n",
      "           Conv2d-15          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 16, 216]             128\n",
      "             ReLU-17          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-18          [-1, 64, 16, 216]               0\n",
      "           Conv2d-19          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-20          [-1, 64, 16, 216]             128\n",
      "             ReLU-21          [-1, 64, 16, 216]               0\n",
      "           Conv2d-22          [-1, 64, 16, 216]          36,864\n",
      "      BatchNorm2d-23          [-1, 64, 16, 216]             128\n",
      "             ReLU-24          [-1, 64, 16, 216]               0\n",
      "       BasicBlock-25          [-1, 64, 16, 216]               0\n",
      "           Conv2d-26          [-1, 128, 8, 108]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 8, 108]             256\n",
      "             ReLU-28          [-1, 128, 8, 108]               0\n",
      "           Conv2d-29          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 8, 108]             256\n",
      "           Conv2d-31          [-1, 128, 8, 108]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 8, 108]             256\n",
      "             ReLU-33          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-34          [-1, 128, 8, 108]               0\n",
      "           Conv2d-35          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 8, 108]             256\n",
      "             ReLU-37          [-1, 128, 8, 108]               0\n",
      "           Conv2d-38          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 8, 108]             256\n",
      "             ReLU-40          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-41          [-1, 128, 8, 108]               0\n",
      "           Conv2d-42          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 8, 108]             256\n",
      "             ReLU-44          [-1, 128, 8, 108]               0\n",
      "           Conv2d-45          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 8, 108]             256\n",
      "             ReLU-47          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-48          [-1, 128, 8, 108]               0\n",
      "           Conv2d-49          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 8, 108]             256\n",
      "             ReLU-51          [-1, 128, 8, 108]               0\n",
      "           Conv2d-52          [-1, 128, 8, 108]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 8, 108]             256\n",
      "             ReLU-54          [-1, 128, 8, 108]               0\n",
      "       BasicBlock-55          [-1, 128, 8, 108]               0\n",
      "           Conv2d-56           [-1, 256, 4, 54]         294,912\n",
      "      BatchNorm2d-57           [-1, 256, 4, 54]             512\n",
      "             ReLU-58           [-1, 256, 4, 54]               0\n",
      "           Conv2d-59           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-60           [-1, 256, 4, 54]             512\n",
      "           Conv2d-61           [-1, 256, 4, 54]          32,768\n",
      "      BatchNorm2d-62           [-1, 256, 4, 54]             512\n",
      "             ReLU-63           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-64           [-1, 256, 4, 54]               0\n",
      "           Conv2d-65           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-66           [-1, 256, 4, 54]             512\n",
      "             ReLU-67           [-1, 256, 4, 54]               0\n",
      "           Conv2d-68           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-69           [-1, 256, 4, 54]             512\n",
      "             ReLU-70           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-71           [-1, 256, 4, 54]               0\n",
      "           Conv2d-72           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-73           [-1, 256, 4, 54]             512\n",
      "             ReLU-74           [-1, 256, 4, 54]               0\n",
      "           Conv2d-75           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-76           [-1, 256, 4, 54]             512\n",
      "             ReLU-77           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-78           [-1, 256, 4, 54]               0\n",
      "           Conv2d-79           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-80           [-1, 256, 4, 54]             512\n",
      "             ReLU-81           [-1, 256, 4, 54]               0\n",
      "           Conv2d-82           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-83           [-1, 256, 4, 54]             512\n",
      "             ReLU-84           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-85           [-1, 256, 4, 54]               0\n",
      "           Conv2d-86           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-87           [-1, 256, 4, 54]             512\n",
      "             ReLU-88           [-1, 256, 4, 54]               0\n",
      "           Conv2d-89           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-90           [-1, 256, 4, 54]             512\n",
      "             ReLU-91           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-92           [-1, 256, 4, 54]               0\n",
      "           Conv2d-93           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-94           [-1, 256, 4, 54]             512\n",
      "             ReLU-95           [-1, 256, 4, 54]               0\n",
      "           Conv2d-96           [-1, 256, 4, 54]         589,824\n",
      "      BatchNorm2d-97           [-1, 256, 4, 54]             512\n",
      "             ReLU-98           [-1, 256, 4, 54]               0\n",
      "       BasicBlock-99           [-1, 256, 4, 54]               0\n",
      "          Conv2d-100           [-1, 512, 2, 27]       1,179,648\n",
      "     BatchNorm2d-101           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-102           [-1, 512, 2, 27]               0\n",
      "          Conv2d-103           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-104           [-1, 512, 2, 27]           1,024\n",
      "          Conv2d-105           [-1, 512, 2, 27]         131,072\n",
      "     BatchNorm2d-106           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-107           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-108           [-1, 512, 2, 27]               0\n",
      "          Conv2d-109           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-110           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-111           [-1, 512, 2, 27]               0\n",
      "          Conv2d-112           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-113           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-114           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-115           [-1, 512, 2, 27]               0\n",
      "          Conv2d-116           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-117           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-118           [-1, 512, 2, 27]               0\n",
      "          Conv2d-119           [-1, 512, 2, 27]       2,359,296\n",
      "     BatchNorm2d-120           [-1, 512, 2, 27]           1,024\n",
      "            ReLU-121           [-1, 512, 2, 27]               0\n",
      "      BasicBlock-122           [-1, 512, 2, 27]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.63\n",
      "Forward/backward pass size (MB): 106.06\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 187.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming 'model' is your PyTorch model\n",
    "summary(model, input_size=(3, 64, 862))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:11:53.400002300Z",
     "start_time": "2023-10-13T09:11:53.323702500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pad_waveform(waveform, target_length):\n",
    "    num_channels, current_length = waveform.shape\n",
    "\n",
    "    if current_length < target_length:\n",
    "        # Calculate the amount of padding needed\n",
    "        padding = target_length - current_length\n",
    "        # Pad the waveform with zeros on the right side\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "\n",
    "    return waveform\n",
    "\n",
    "# Define a function to transform audio data into images\n",
    "def transform_data_to_image(audio, sample_rate, label, i):\n",
    "    # Pad waveform to a consistent length of 44100 samples\n",
    "    audio = pad_waveform(audio, 441000)\n",
    "\n",
    "    spectrogram_tensor = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=64, n_fft=1024)(audio)[0] + 1e-10\n",
    "\n",
    "    # Save the spectrogram as an image\n",
    "    image_path = f'Data/TestImages/{label}/image{i}.png'\n",
    "\n",
    "    plt.imsave(image_path, spectrogram_tensor.log2().numpy(), cmap='viridis')\n",
    "    return image_path\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 862)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x[:3, :, :])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:11:56.818685800Z",
     "start_time": "2023-10-13T09:11:56.189334100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                Filename  Prediction\n0    ---1_cCGK4M_out.wav           1\n1    -20uudT97E0_out.wav           0\n2    -2yygHLdpXc_out.wav           1\n3    -3bGlOhRkAo_out.wav           1\n4    -4pUrlMafww_out.wav           1\n..                   ...         ...\n857  _QMEw67gWIA_out.wav           1\n858  _TLzbbay6Hw_out.wav           1\n859  _XPPISqmXSE_out.wav           1\n860  _xRpsu02t9o_out.wav           1\n861  _zzhHu7HwZc_out.wav           0\n\n[862 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>---1_cCGK4M_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-20uudT97E0_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2yygHLdpXc_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-3bGlOhRkAo_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-4pUrlMafww_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>_QMEw67gWIA_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>_TLzbbay6Hw_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>859</th>\n      <td>_XPPISqmXSE_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>_xRpsu02t9o_out.wav</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>_zzhHu7HwZc_out.wav</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>862 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/Screaming'  # Replace with the path to your folder\n",
    "label = 'Screaming'  # Label for the images\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "scream_predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "scream_predictions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:13:00.720478Z",
     "start_time": "2023-10-13T09:11:59.847570300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Prediction\n1    824\n0     38\nName: count, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scream_predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:13:16.657521800Z",
     "start_time": "2023-10-13T09:13:16.650245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Filename  Prediction\n0     --PJHxphWEs_out.wav           0\n1     -28U1_qW0sU_out.wav           0\n2     -4xJv59_zcA_out.wav           0\n3     -5GhUbDLYkQ_out.wav           0\n4     -5Jlimvsuwo_out.wav           0\n...                   ...         ...\n2626  _XusTa2prSw_out.wav           0\n2627  _y07ENAx2_E_out.wav           0\n2628  _yqlQimkHpQ_out.wav           0\n2629  _Zsk5Fxqbkc_out.wav           0\n2630  __qxgIqI0uA_out.wav           0\n\n[2631 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>--PJHxphWEs_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-28U1_qW0sU_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-4xJv59_zcA_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-5GhUbDLYkQ_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-5Jlimvsuwo_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2626</th>\n      <td>_XusTa2prSw_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2627</th>\n      <td>_y07ENAx2_E_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2628</th>\n      <td>_yqlQimkHpQ_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2629</th>\n      <td>_Zsk5Fxqbkc_out.wav</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2630</th>\n      <td>__qxgIqI0uA_out.wav</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2631 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the folder containing WAV files\n",
    "folder_path = 'Data/NotScreaming'  # Replace with the path to your folder\n",
    "label = 'NotScreaming'  # Label for the images\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store data\n",
    "predictions_data = []\n",
    "\n",
    "# Iterate through WAV files in the folder\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Load the audio\n",
    "        audio, sample_rate = torchaudio.load(os.path.join(folder_path, filename))\n",
    "\n",
    "        # Transform audio to an image and save it\n",
    "        image_path = transform_data_to_image(audio, sample_rate, label, i)\n",
    "\n",
    "        # Load the saved image and apply transformations\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make predictions using the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.to(device))\n",
    "\n",
    "        predict = outputs.argmax(dim=1).cpu().detach().numpy().ravel()[0]\n",
    "\n",
    "        # Store the filename and prediction in the DataFrame\n",
    "        predictions_data.append({'Filename': filename, 'Prediction': predict})\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "not_scream_predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "not_scream_predictions_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:16:18.386493900Z",
     "start_time": "2023-10-13T09:13:21.695946900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Prediction\n0    2556\n1      75\nName: count, dtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_scream_predictions_df['Prediction'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:16:39.074655200Z",
     "start_time": "2023-10-13T09:16:39.063960200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Compute TP, FP, TN, FN for Scream predictions\n",
    "scream_TP = scream_predictions_df['Prediction'].value_counts().get(1, 0)\n",
    "scream_FN = scream_predictions_df['Prediction'].value_counts().get(0, 0)\n",
    "scream_samples = len(scream_predictions_df)\n",
    "\n",
    "# Compute TP, FP, TN, FN for Not Scream predictions\n",
    "scream_TN = not_scream_predictions_df['Prediction'].value_counts().get(0, 0)\n",
    "scream_FP = not_scream_predictions_df['Prediction'].value_counts().get(1, 0)\n",
    "not_scream_samples = len(not_scream_predictions_df)\n",
    "\n",
    "# Calculate total samples\n",
    "total_samples = scream_samples + not_scream_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:16:42.233025800Z",
     "start_time": "2023-10-13T09:16:42.228599500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Precision: 0.92\n",
      "Recall: 0.96\n",
      "F1 Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (scream_TP + scream_TN) / total_samples\n",
    "\n",
    "# Calculate precision\n",
    "precision = scream_TP / (scream_TP + scream_FP)\n",
    "\n",
    "# Calculate recall\n",
    "recall = scream_TP / (scream_TP + scream_FN)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:16:45.122168800Z",
     "start_time": "2023-10-13T09:16:45.119357300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
